Basic Usage Examples
====================

This section provides basic usage examples for the ACFX package. These examples demonstrate how to initialize the ACFX class to generate counterfactual explanations.

Initializing ACFX
-----------------

To begin using ACFX, first import the class and create an instance.
For this example, let's pick AcfxEBM that requires ExplainableBoostingClassifier as its blackbox:

.. code-block:: python

    from acfx import AcfxEBM

    model = ExplainableBoostingClassifier()
    explainer = AcfxEBM(model)

Prepare the data
----------------

Prepare some sample data for for counterfactual generation

.. code-block:: python

    from sklearn.datasets import load_iris
    def sample_data():
        data = load_iris(as_frame=True)
        X = data.data
        y = data.target
        return train_test_split(X, y, test_size=0.2, random_state=42)

        X_train, X_test, y_train, y_test = sample_data

Prepare bounds
--------------

Prepare bounds for data for counterfactual generation

.. code-block:: python

    pbounds = {col: (X_train[col].min(), X_train[col].max()) for col in X_train.columns}

Prepare adjacency matrix
------------------------
Prepare example adjacency matrix for counterfactual generation. It can be expert knowledge or can be generated by tools like DirectLiNGAM

.. code-block:: python

    adjacency_matrix = np.array([
        [0.0, 0.0, 0.0, 0.0],
        [0.8, 0.0, 0.0, 0.0],
        [0.0, 0.6, 0.0, 0.0],
        [0.5, 0.0, 0.7, 0.0]
    ])

(Alternatively) prepare adjacency matrix using external tools
-------------------------------------------------------------
The adjacency matrix can be generated by tools like DirectLiNGAM

.. code-block:: python

    causal_model = lingam.DirectLiNGAM()
    causal_model.fit(X_train)

    adjacency_matrix = causal_model.adjacency_matrix_


Prepare the order of variables in the causal graph
--------------------------------------------------

.. code-block:: python

    causal_order = list(range(len(features_order)))

Fit to initialize the model
---------------------------

Initialize all the prepared data

.. code-block:: python


    features_order = X_train.columns.tolist()
    explainer.fit(X=X_train, adjacency_matrix=adjacency_matrix, causal_order=causal_order, pbounds=pbounds,
                  y=y_train, features_order=features_order)

Generate Counterfactuals
------------------------

To generate counterfactual explanations for a given instance:

.. code-block:: python

    original_class = model.predict([query_instance])[0]

    cf = explainer.counterfactual(desired_class=original_class, query_instance=query_instance)
    print(cf)


Using custom blackbox
---------------------

You can use ACFX with custom blackbox. To do so, you need to provide a optimizer that is compliant with the blackbox

Example custom optimizer
------------------------

Below I prepared an example custom optimizer

.. code-block:: python

    class SomeCustomCounterOptimizer(ModelBasedCounterOptimizer):
        def __init__(self, model, X: pd.DataFrame, feature_bounds: Dict[str, Tuple[float, float]], n_iter: int = 100):
            self.model = model
            self.X = X
            self.feature_bounds = feature_bounds
            self.n_iter = n_iter

        @overrides
        def optimize_proba(self, target_class: int, feature_masked: list[str]):
            base_instance = self.X.mean().copy()
            best_instance = base_instance.copy()
            best_score = self.model.predict_proba([base_instance])[0][target_class]

            for _ in range(self.n_iter):
                candidate = base_instance.copy()
                for feature_name in self.X.columns:
                    if feature_name not in feature_masked and feature_name in self.feature_bounds:
                        min_val, max_val = self.feature_bounds[feature_name]
                        candidate[feature_name] = np.random.uniform(min_val, max_val)

                score = self.model.predict_proba([candidate])[0][target_class]
                if score > best_score:
                    best_score = score
                    best_instance = candidate.copy()

            return best_instance.to_numpy()

...and example acfx explainer's fit

.. code-block:: python

    model = RandomForestClassifier(n_estimators=100)
    model.fit(X_train, y_train)

    feature_masked = ["sepal width (cm)"]
    optimizer = SomeCustomCounterOptimizer(model, X_test, pbounds)

    explainer = AcfxCustom(model)
    explainer.fit(X=X_train, adjacency_matrix=adjacency_matrix, causal_order=causal_order, pbounds=pbounds,
                  features_order=features_order, optimizer=optimizer, masked_features=feature_masked)
